{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtcy/w/+A0PLSKp8hN/1EW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krahul2024/random_repo/blob/usacoCodes/dm/codes/entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Mounting google drive to make drive files availabe to\n",
        "for reading and writing purpose\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ALrYmqWnw4AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_url = \"/content/drive/MyDrive/Colab Notebooks/dm/datasets/iris.csv\"\n",
        "data_frame = pd.read_csv(drive_url)  \n",
        "if(not data_frame.empty): print(\"\\nDataframe is not empty.\")\n",
        "else: print(\"Dataframe is empty.\")"
      ],
      "metadata": {
        "id": "Ccp0aT-rqaiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math \n",
        "def entropy_column(value):\n",
        "\t\tlst = list(value)\n",
        "\t\tdictionary = dict() #creating a dictionary for storing key values and pairs \n",
        "\t\tfor i in  range(len(lst)):\n",
        "\t\t\tdictionary[lst[i]] = [0,0] # initializing dictionary as first element is count and second is entropy for respective key\n",
        "\n",
        "\t\t# updating counts of each element \n",
        "\t\tfor i in range(len(lst)):\n",
        "\t\t\ttemp = dictionary[lst[i]] \n",
        "\t\t\ttemp[0] = temp[0] + 1 \n",
        "\t\t\tdictionary[lst[i]] = temp \n",
        "\n",
        "\t\t# calculating entropy for each element using the formula plogp\n",
        "\t\tfor val in dictionary:\n",
        "\t\t\tprob = dictionary[val][0]/150  \n",
        "\t\t\tprob = prob*(math.log2(prob))\n",
        "\t\t\tdictionary[val][1] = prob\n",
        "\n",
        "\t\t# for item in dictionary:\n",
        "\t\t# \tprint('value:',item,',Count:',dictionary[item][0],'Entropy:',dictionary[item][1],'\\n') \n",
        "\n",
        "\t\treturn dictionary  # returning dictionary which has labels and entropy for each of the label \n",
        "\t\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "# this is for reading from github as this makes file import easier and reduces pain of uploading file again and again in below case\n",
        "file_url = \"https://raw.githubusercontent.com/krahul2024/random_repo/usacoCodes/dm/datasets/iris.csv\"\n",
        "df = pd.read_csv(file_url) \n",
        "# while using this method we will have to upload file every time we will run this code segment\n",
        "# uploaded = files.upload()\n",
        "# df=pd.read_csv(r'iris.csv')\n",
        "# print(df.shape) #this prints shape of the dataset in terms of rows and columns \n",
        "\n",
        "#inputs \n",
        "label = df[\"Species\"] \n",
        "df.drop(\"Species\" , axis = 1 , inplace = True)  \n",
        "df.drop(\"Id\",axis=1,inplace=True) \n",
        "# print(df.shape)\n",
        "\n",
        "# print(label.value_counts)  \n",
        "#label.value_counts().plot(kind=bar) \n",
        "features = set(df.columns) \n",
        "# print(features) \n",
        "scaler = MinMaxScaler() \n",
        "df_norm = df.copy() \n",
        "df_norm[list(features)] = scaler.fit_transform(df[list(features)])\n",
        "#find entropy of labels or the flower species types \n",
        "\n",
        "list_of_labels = list(features) \n",
        "\n",
        "print('value , count , entropy For Label \\n',entropy_column(label),'\\n')\n",
        "for i in range(len(list_of_labels)):\n",
        "  print('value , count , entropy for each of unique values')\n",
        "  print('For ', list_of_labels[i], '\\n',entropy_column(df[list_of_labels[i]]),'\\n')\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1pld7_lzmlOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"this i s the change in this file and it must be seen if the file is pushed to github\")"
      ],
      "metadata": {
        "id": "KcXz063p0xM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPGtqoDJ6Ce8"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}